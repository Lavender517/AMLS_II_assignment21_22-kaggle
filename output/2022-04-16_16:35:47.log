Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading training data ...
Using BERT Model
start training, parameter total:109483009, trainable:109483009
[ Epoch1: 1/96 ] loss:0.491 acc:56.250 [ Epoch1: 2/96 ] loss:0.445 acc:54.688 [ Epoch1: 3/96 ] loss:0.406 acc:59.375 [ Epoch1: 4/96 ] loss:0.306 acc:67.188 [ Epoch1: 5/96 ] loss:0.384 acc:51.562 [ Epoch1: 6/96 ] loss:0.334 acc:60.938 [ Epoch1: 7/96 ] loss:0.334 acc:51.562 [ Epoch1: 8/96 ] loss:0.268 acc:59.375 [ Epoch1: 9/96 ] loss:0.258 acc:62.500 [ Epoch1: 10/96 ] loss:0.243 acc:64.062 [ Epoch1: 11/96 ] loss:0.247 acc:59.375 [ Epoch1: 12/96 ] loss:0.211 acc:68.750 [ Epoch1: 13/96 ] loss:0.276 acc:53.125 [ Epoch1: 14/96 ] loss:0.277 acc:50.000 [ Epoch1: 15/96 ] loss:0.269 acc:48.438 [ Epoch1: 16/96 ] loss:0.220 acc:62.500 [ Epoch1: 17/96 ] loss:0.289 acc:48.438 [ Epoch1: 18/96 ] loss:0.263 acc:46.875 [ Epoch1: 19/96 ] loss:0.278 acc:46.875 [ Epoch1: 20/96 ] loss:0.237 acc:60.938 [ Epoch1: 21/96 ] loss:0.229 acc:59.375 [ Epoch1: 22/96 ] loss:0.236 acc:62.500 [ Epoch1: 23/96 ] loss:0.284 acc:43.750 [ Epoch1: 24/96 ] loss:0.284 acc:54.688 [ Epoch1: 25/96 ] loss:0.251 acc:54.688 [ Epoch1: 26/96 ] loss:0.238 acc:67.188 [ Epoch1: 27/96 ] loss:0.227 acc:60.938 [ Epoch1: 28/96 ] loss:0.238 acc:59.375 [ Epoch1: 29/96 ] loss:0.240 acc:56.250 [ Epoch1: 30/96 ] loss:0.220 acc:59.375 [ Epoch1: 31/96 ] loss:0.269 acc:54.688 [ Epoch1: 32/96 ] loss:0.197 acc:71.875 [ Epoch1: 33/96 ] loss:0.212 acc:71.875 [ Epoch1: 34/96 ] loss:0.209 acc:67.188 [ Epoch1: 35/96 ] loss:0.251 acc:57.812 [ Epoch1: 36/96 ] loss:0.226 acc:62.500 [ Epoch1: 37/96 ] loss:0.257 acc:59.375 [ Epoch1: 38/96 ] loss:0.222 acc:64.062 [ Epoch1: 39/96 ] loss:0.212 acc:67.188 [ Epoch1: 40/96 ] loss:0.230 acc:65.625 [ Epoch1: 41/96 ] loss:0.224 acc:64.062 [ Epoch1: 42/96 ] loss:0.205 acc:71.875 [ Epoch1: 43/96 ] loss:0.196 acc:70.312 [ Epoch1: 44/96 ] loss:0.210 acc:65.625 [ Epoch1: 45/96 ] loss:0.151 acc:81.250 [ Epoch1: 46/96 ] loss:0.213 acc:73.438 [ Epoch1: 47/96 ] loss:0.204 acc:67.188 [ Epoch1: 48/96 ] loss:0.234 acc:60.938 [ Epoch1: 49/96 ] loss:0.214 acc:65.625 [ Epoch1: 50/96 ] loss:0.161 acc:76.562 [ Epoch1: 51/96 ] loss:0.215 acc:71.875 [ Epoch1: 52/96 ] loss:0.186 acc:73.438 [ Epoch1: 53/96 ] loss:0.215 acc:65.625 [ Epoch1: 54/96 ] loss:0.204 acc:71.875 [ Epoch1: 55/96 ] loss:0.186 acc:71.875 [ Epoch1: 56/96 ] loss:0.208 acc:71.875 [ Epoch1: 57/96 ] loss:0.174 acc:73.438 [ Epoch1: 58/96 ] loss:0.168 acc:70.312 [ Epoch1: 59/96 ] loss:0.184 acc:71.875 [ Epoch1: 60/96 ] loss:0.212 acc:68.750 [ Epoch1: 61/96 ] loss:0.161 acc:79.688 [ Epoch1: 62/96 ] loss:0.210 acc:71.875 [ Epoch1: 63/96 ] loss:0.127 acc:85.938 [ Epoch1: 64/96 ] loss:0.182 acc:76.562 [ Epoch1: 65/96 ] loss:0.153 acc:75.000 [ Epoch1: 66/96 ] loss:0.197 acc:70.312 [ Epoch1: 67/96 ] loss:0.170 acc:78.125 [ Epoch1: 68/96 ] loss:0.179 acc:75.000 [ Epoch1: 69/96 ] loss:0.142 acc:79.688 [ Epoch1: 70/96 ] loss:0.173 acc:76.562 [ Epoch1: 71/96 ] loss:0.185 acc:71.875 [ Epoch1: 72/96 ] loss:0.107 acc:87.500 [ Epoch1: 73/96 ] loss:0.183 acc:75.000 [ Epoch1: 74/96 ] loss:0.192 acc:71.875 [ Epoch1: 75/96 ] loss:0.182 acc:68.750 [ Epoch1: 76/96 ] loss:0.134 acc:81.250 [ Epoch1: 77/96 ] loss:0.203 acc:70.312 [ Epoch1: 78/96 ] loss:0.162 acc:82.812 [ Epoch1: 79/96 ] loss:0.179 acc:75.000 [ Epoch1: 80/96 ] loss:0.214 acc:68.750 [ Epoch1: 81/96 ] loss:0.160 acc:79.688 [ Epoch1: 82/96 ] loss:0.175 acc:76.562 [ Epoch1: 83/96 ] loss:0.181 acc:75.000 [ Epoch1: 84/96 ] loss:0.178 acc:76.562 [ Epoch1: 85/96 ] loss:0.187 acc:75.000 [ Epoch1: 86/96 ] loss:0.169 acc:75.000 [ Epoch1: 87/96 ] loss:0.231 acc:68.750 [ Epoch1: 88/96 ] loss:0.186 acc:76.562 [ Epoch1: 89/96 ] loss:0.169 acc:73.438 [ Epoch1: 90/96 ] loss:0.186 acc:73.438 [ Epoch1: 91/96 ] loss:0.190 acc:75.000 [ Epoch1: 92/96 ] loss:0.228 acc:65.625 [ Epoch1: 93/96 ] loss:0.138 acc:81.250 [ Epoch1: 94/96 ] loss:0.169 acc:73.438 [ Epoch1: 95/96 ] loss:0.166 acc:76.562 [ Epoch1: 96/96 ] loss:0.242 acc:10.938 
Train | Loss:0.22003 Acc: 66.829
Valid | Loss:0.15925 Acc: 77.734 
saving model with acc 77.734
-----------------------------------------------
[ Epoch2: 1/96 ] loss:0.147 acc:85.938 [ Epoch2: 2/96 ] loss:0.189 acc:75.000 [ Epoch2: 3/96 ] loss:0.230 acc:65.625 [ Epoch2: 4/96 ] loss:0.174 acc:71.875 [ Epoch2: 5/96 ] loss:0.147 acc:81.250 [ Epoch2: 6/96 ] loss:0.148 acc:81.250 [ Epoch2: 7/96 ] loss:0.132 acc:84.375 [ Epoch2: 8/96 ] loss:0.196 acc:67.188 [ Epoch2: 9/96 ] loss:0.165 acc:78.125 [ Epoch2: 10/96 ] loss:0.161 acc:79.688 [ Epoch2: 11/96 ] loss:0.192 acc:71.875 [ Epoch2: 12/96 ] loss:0.167 acc:76.562 [ Epoch2: 13/96 ] loss:0.163 acc:78.125 [ Epoch2: 14/96 ] loss:0.147 acc:84.375 [ Epoch2: 15/96 ] loss:0.167 acc:78.125 [ Epoch2: 16/96 ] loss:0.168 acc:76.562 [ Epoch2: 17/96 ] loss:0.160 acc:81.250 [ Epoch2: 18/96 ] loss:0.125 acc:85.938 [ Epoch2: 19/96 ] loss:0.216 acc:65.625 [ Epoch2: 20/96 ] loss:0.171 acc:78.125 [ Epoch2: 21/96 ] loss:0.131 acc:84.375 [ Epoch2: 22/96 ] loss:0.189 acc:73.438 [ Epoch2: 23/96 ] loss:0.124 acc:87.500 [ Epoch2: 24/96 ] loss:0.140 acc:82.812 [ Epoch2: 25/96 ] loss:0.182 acc:76.562 [ Epoch2: 26/96 ] loss:0.194 acc:71.875 [ Epoch2: 27/96 ] loss:0.160 acc:78.125 [ Epoch2: 28/96 ] loss:0.144 acc:82.812 [ Epoch2: 29/96 ] loss:0.172 acc:75.000 [ Epoch2: 30/96 ] loss:0.181 acc:75.000 [ Epoch2: 31/96 ] loss:0.179 acc:75.000 [ Epoch2: 32/96 ] loss:0.143 acc:84.375 [ Epoch2: 33/96 ] loss:0.175 acc:78.125 [ Epoch2: 34/96 ] loss:0.126 acc:82.812 [ Epoch2: 35/96 ] loss:0.241 acc:64.062 [ Epoch2: 36/96 ] loss:0.186 acc:70.312 [ Epoch2: 37/96 ] loss:0.178 acc:73.438 [ Epoch2: 38/96 ] loss:0.143 acc:84.375 [ Epoch2: 39/96 ] loss:0.153 acc:81.250 [ Epoch2: 40/96 ] loss:0.134 acc:79.688 [ Epoch2: 41/96 ] loss:0.147 acc:84.375 [ Epoch2: 42/96 ] loss:0.095 acc:85.938 [ Epoch2: 43/96 ] loss:0.166 acc:79.688 [ Epoch2: 44/96 ] loss:0.148 acc:78.125 [ Epoch2: 45/96 ] loss:0.163 acc:79.688 [ Epoch2: 46/96 ] loss:0.117 acc:84.375 [ Epoch2: 47/96 ] loss:0.151 acc:81.250 [ Epoch2: 48/96 ] loss:0.197 acc:78.125 [ Epoch2: 49/96 ] loss:0.122 acc:84.375 [ Epoch2: 50/96 ] loss:0.193 acc:76.562 [ Epoch2: 51/96 ] loss:0.113 acc:84.375 [ Epoch2: 52/96 ] loss:0.149 acc:81.250 [ Epoch2: 53/96 ] loss:0.170 acc:78.125 [ Epoch2: 54/96 ] loss:0.144 acc:79.688 [ Epoch2: 55/96 ] loss:0.143 acc:81.250 [ Epoch2: 56/96 ] loss:0.159 acc:76.562 [ Epoch2: 57/96 ] loss:0.098 acc:89.062 [ Epoch2: 58/96 ] loss:0.166 acc:73.438 [ Epoch2: 59/96 ] loss:0.131 acc:84.375 [ Epoch2: 60/96 ] loss:0.157 acc:81.250 [ Epoch2: 61/96 ] loss:0.142 acc:79.688 [ Epoch2: 62/96 ] loss:0.198 acc:71.875 [ Epoch2: 63/96 ] loss:0.169 acc:79.688 [ Epoch2: 64/96 ] loss:0.131 acc:81.250 [ Epoch2: 65/96 ] loss:0.118 acc:87.500 [ Epoch2: 66/96 ] loss:0.144 acc:79.688 [ Epoch2: 67/96 ] loss:0.158 acc:76.562 [ Epoch2: 68/96 ] loss:0.133 acc:84.375 [ Epoch2: 69/96 ] loss:0.143 acc:78.125 [ Epoch2: 70/96 ] loss:0.145 acc:79.688 [ Epoch2: 71/96 ] loss:0.126 acc:82.812 [ Epoch2: 72/96 ] loss:0.154 acc:79.688 [ Epoch2: 73/96 ] loss:0.166 acc:73.438 [ Epoch2: 74/96 ] loss:0.152 acc:78.125 [ Epoch2: 75/96 ] loss:0.195 acc:75.000 [ Epoch2: 76/96 ] loss:0.157 acc:76.562 [ Epoch2: 77/96 ] loss:0.155 acc:82.812 [ Epoch2: 78/96 ] loss:0.141 acc:78.125 [ Epoch2: 79/96 ] loss:0.163 acc:76.562 [ Epoch2: 80/96 ] loss:0.126 acc:84.375 [ Epoch2: 81/96 ] loss:0.122 acc:85.938 [ Epoch2: 82/96 ] loss:0.180 acc:75.000 [ Epoch2: 83/96 ] loss:0.179 acc:79.688 [ Epoch2: 84/96 ] loss:0.115 acc:87.500 [ Epoch2: 85/96 ] loss:0.169 acc:76.562 [ Epoch2: 86/96 ] loss:0.159 acc:76.562 [ Epoch2: 87/96 ] loss:0.121 acc:84.375 [ Epoch2: 88/96 ] loss:0.100 acc:85.938 [ Epoch2: 89/96 ] loss:0.181 acc:78.125 [ Epoch2: 90/96 ] loss:0.148 acc:78.125 [ Epoch2: 91/96 ] loss:0.147 acc:79.688 [ Epoch2: 92/96 ] loss:0.130 acc:79.688 [ Epoch2: 93/96 ] loss:0.136 acc:79.688 [ Epoch2: 94/96 ] loss:0.113 acc:85.938 [ Epoch2: 95/96 ] loss:0.099 acc:87.500 [ Epoch2: 96/96 ] loss:0.167 acc:12.500 
Train | Loss:0.15471 Acc: 78.630
Valid | Loss:0.15008 Acc: 79.167 
saving model with acc 79.167
-----------------------------------------------
[ Epoch3: 1/96 ] loss:0.126 acc:84.375 [ Epoch3: 2/96 ] loss:0.110 acc:84.375 [ Epoch3: 3/96 ] loss:0.219 acc:67.188 [ Epoch3: 4/96 ] loss:0.177 acc:76.562 [ Epoch3: 5/96 ] loss:0.200 acc:68.750 [ Epoch3: 6/96 ] loss:0.114 acc:85.938 [ Epoch3: 7/96 ] loss:0.152 acc:81.250 [ Epoch3: 8/96 ] loss:0.168 acc:81.250 [ Epoch3: 9/96 ] loss:0.115 acc:84.375 [ Epoch3: 10/96 ] loss:0.152 acc:78.125 [ Epoch3: 11/96 ] loss:0.192 acc:70.312 [ Epoch3: 12/96 ] loss:0.169 acc:75.000 [ Epoch3: 13/96 ] loss:0.098 acc:87.500 [ Epoch3: 14/96 ] loss:0.157 acc:78.125 [ Epoch3: 15/96 ] loss:0.136 acc:81.250 [ Epoch3: 16/96 ] loss:0.165 acc:75.000 [ Epoch3: 17/96 ] loss:0.070 acc:95.312 [ Epoch3: 18/96 ] loss:0.172 acc:78.125 [ Epoch3: 19/96 ] loss:0.098 acc:87.500 [ Epoch3: 20/96 ] loss:0.157 acc:78.125 [ Epoch3: 21/96 ] loss:0.179 acc:70.312 [ Epoch3: 22/96 ] loss:0.128 acc:82.812 [ Epoch3: 23/96 ] loss:0.175 acc:73.438 [ Epoch3: 24/96 ] loss:0.202 acc:70.312 [ Epoch3: 25/96 ] loss:0.115 acc:84.375 [ Epoch3: 26/96 ] loss:0.134 acc:79.688 [ Epoch3: 27/96 ] loss:0.129 acc:81.250 [ Epoch3: 28/96 ] loss:0.117 acc:81.250 [ Epoch3: 29/96 ] loss:0.090 acc:93.750 [ Epoch3: 30/96 ] loss:0.180 acc:75.000 [ Epoch3: 31/96 ] loss:0.160 acc:79.688 [ Epoch3: 32/96 ] loss:0.182 acc:71.875 [ Epoch3: 33/96 ] loss:0.160 acc:76.562 [ Epoch3: 34/96 ] loss:0.180 acc:68.750 [ Epoch3: 35/96 ] loss:0.148 acc:78.125 [ Epoch3: 36/96 ] loss:0.158 acc:76.562 [ Epoch3: 37/96 ] loss:0.138 acc:79.688 [ Epoch3: 38/96 ] loss:0.138 acc:81.250 [ Epoch3: 39/96 ] loss:0.198 acc:68.750 [ Epoch3: 40/96 ] loss:0.111 acc:84.375 [ Epoch3: 41/96 ] loss:0.147 acc:79.688 [ Epoch3: 42/96 ] loss:0.133 acc:82.812 [ Epoch3: 43/96 ] loss:0.157 acc:76.562 [ Epoch3: 44/96 ] loss:0.134 acc:82.812 [ Epoch3: 45/96 ] loss:0.100 acc:85.938 [ Epoch3: 46/96 ] loss:0.136 acc:82.812 [ Epoch3: 47/96 ] loss:0.123 acc:85.938 [ Epoch3: 48/96 ] loss:0.130 acc:79.688 [ Epoch3: 49/96 ] loss:0.104 acc:87.500 [ Epoch3: 50/96 ] loss:0.119 acc:79.688 [ Epoch3: 51/96 ] loss:0.147 acc:81.250 [ Epoch3: 52/96 ] loss:0.079 acc:93.750 [ Epoch3: 53/96 ] loss:0.101 acc:85.938 [ Epoch3: 54/96 ] loss:0.156 acc:78.125 [ Epoch3: 55/96 ] loss:0.158 acc:78.125 [ Epoch3: 56/96 ] loss:0.143 acc:79.688 [ Epoch3: 57/96 ] loss:0.156 acc:78.125 [ Epoch3: 58/96 ] loss:0.129 acc:87.500 [ Epoch3: 59/96 ] loss:0.144 acc:82.812 [ Epoch3: 60/96 ] loss:0.172 acc:76.562 [ Epoch3: 61/96 ] loss:0.089 acc:90.625 [ Epoch3: 62/96 ] loss:0.104 acc:84.375 [ Epoch3: 63/96 ] loss:0.150 acc:79.688 [ Epoch3: 64/96 ] loss:0.127 acc:79.688 [ Epoch3: 65/96 ] loss:0.171 acc:79.688 [ Epoch3: 66/96 ] loss:0.147 acc:84.375 [ Epoch3: 67/96 ] loss:0.153 acc:76.562 [ Epoch3: 68/96 ] loss:0.122 acc:84.375 [ Epoch3: 69/96 ] loss:0.156 acc:78.125 [ Epoch3: 70/96 ] loss:0.123 acc:84.375 [ Epoch3: 71/96 ] loss:0.116 acc:81.250 [ Epoch3: 72/96 ] loss:0.155 acc:79.688 [ Epoch3: 73/96 ] loss:0.099 acc:89.062 [ Epoch3: 74/96 ] loss:0.086 acc:87.500 [ Epoch3: 75/96 ] loss:0.085 acc:87.500 [ Epoch3: 76/96 ] loss:0.109 acc:84.375 [ Epoch3: 77/96 ] loss:0.169 acc:75.000 [ Epoch3: 78/96 ] loss:0.168 acc:76.562 [ Epoch3: 79/96 ] loss:0.098 acc:87.500 [ Epoch3: 80/96 ] loss:0.128 acc:78.125 [ Epoch3: 81/96 ] loss:0.116 acc:85.938 [ Epoch3: 82/96 ] loss:0.140 acc:82.812 [ Epoch3: 83/96 ] loss:0.105 acc:87.500 [ Epoch3: 84/96 ] loss:0.121 acc:84.375 [ Epoch3: 85/96 ] loss:0.153 acc:82.812 [ Epoch3: 86/96 ] loss:0.137 acc:81.250 [ Epoch3: 87/96 ] loss:0.106 acc:85.938 [ Epoch3: 88/96 ] loss:0.141 acc:84.375 [ Epoch3: 89/96 ] loss:0.141 acc:82.812 [ Epoch3: 90/96 ] loss:0.099 acc:87.500 [ Epoch3: 91/96 ] loss:0.113 acc:85.938 [ Epoch3: 92/96 ] loss:0.170 acc:75.000 [ Epoch3: 93/96 ] loss:0.183 acc:76.562 [ Epoch3: 94/96 ] loss:0.121 acc:79.688 [ Epoch3: 95/96 ] loss:0.151 acc:79.688 [ Epoch3: 96/96 ] loss:0.227 acc:10.938 
Train | Loss:0.13970 Acc: 80.241
Valid | Loss:0.14242 Acc: 79.753 
saving model with acc 79.753
-----------------------------------------------
[ Epoch4: 1/96 ] loss:0.103 acc:90.625 [ Epoch4: 2/96 ] loss:0.128 acc:82.812 [ Epoch4: 3/96 ] loss:0.105 acc:87.500 [ Epoch4: 4/96 ] loss:0.187 acc:71.875 [ Epoch4: 5/96 ] loss:0.218 acc:64.062 [ Epoch4: 6/96 ] loss:0.130 acc:84.375 [ Epoch4: 7/96 ] loss:0.115 acc:85.938 [ Epoch4: 8/96 ] loss:0.155 acc:79.688 [ Epoch4: 9/96 ] loss:0.101 acc:85.938 [ Epoch4: 10/96 ] loss:0.137 acc:81.250 [ Epoch4: 11/96 ] loss:0.143 acc:84.375 [ Epoch4: 12/96 ] loss:0.146 acc:79.688 [ Epoch4: 13/96 ] loss:0.169 acc:76.562 [ Epoch4: 14/96 ] loss:0.107 acc:89.062 [ Epoch4: 15/96 ] loss:0.142 acc:79.688 [ Epoch4: 16/96 ] loss:0.122 acc:87.500 [ Epoch4: 17/96 ] loss:0.099 acc:89.062 [ Epoch4: 18/96 ] loss:0.122 acc:84.375 [ Epoch4: 19/96 ] loss:0.177 acc:75.000 [ Epoch4: 20/96 ] loss:0.114 acc:87.500 [ Epoch4: 21/96 ] loss:0.123 acc:87.500 [ Epoch4: 22/96 ] loss:0.090 acc:90.625 [ Epoch4: 23/96 ] loss:0.102 acc:89.062 [ Epoch4: 24/96 ] loss:0.114 acc:85.938 [ Epoch4: 25/96 ] loss:0.131 acc:84.375 [ Epoch4: 26/96 ] loss:0.139 acc:79.688 [ Epoch4: 27/96 ] loss:0.133 acc:84.375 [ Epoch4: 28/96 ] loss:0.199 acc:71.875 [ Epoch4: 29/96 ] loss:0.143 acc:79.688 [ Epoch4: 30/96 ] loss:0.161 acc:75.000 [ Epoch4: 31/96 ] loss:0.151 acc:76.562 [ Epoch4: 32/96 ] loss:0.186 acc:75.000 [ Epoch4: 33/96 ] loss:0.124 acc:84.375 [ Epoch4: 34/96 ] loss:0.125 acc:82.812 [ Epoch4: 35/96 ] loss:0.099 acc:82.812 [ Epoch4: 36/96 ] loss:0.145 acc:81.250 [ Epoch4: 37/96 ] loss:0.150 acc:79.688 [ Epoch4: 38/96 ] loss:0.118 acc:85.938 [ Epoch4: 39/96 ] loss:0.107 acc:85.938 [ Epoch4: 40/96 ] loss:0.126 acc:82.812 [ Epoch4: 41/96 ] loss:0.140 acc:79.688 [ Epoch4: 42/96 ] loss:0.073 acc:93.750 [ Epoch4: 43/96 ] loss:0.121 acc:82.812 [ Epoch4: 44/96 ] loss:0.137 acc:79.688 [ Epoch4: 45/96 ] loss:0.181 acc:75.000 [ Epoch4: 46/96 ] loss:0.114 acc:85.938 [ Epoch4: 47/96 ] loss:0.128 acc:78.125 [ Epoch4: 48/96 ] loss:0.077 acc:93.750 [ Epoch4: 49/96 ] loss:0.130 acc:82.812 [ Epoch4: 50/96 ] loss:0.194 acc:78.125 [ Epoch4: 51/96 ] loss:0.122 acc:85.938 [ Epoch4: 52/96 ] loss:0.123 acc:84.375 [ Epoch4: 53/96 ] loss:0.105 acc:82.812 [ Epoch4: 54/96 ] loss:0.097 acc:87.500 [ Epoch4: 55/96 ] loss:0.112 acc:82.812 [ Epoch4: 56/96 ] loss:0.111 acc:82.812 [ Epoch4: 57/96 ] loss:0.116 acc:85.938 [ Epoch4: 58/96 ] loss:0.108 acc:87.500 [ Epoch4: 59/96 ] loss:0.123 acc:84.375 [ Epoch4: 60/96 ] loss:0.168 acc:73.438 [ Epoch4: 61/96 ] loss:0.099 acc:85.938 [ Epoch4: 62/96 ] loss:0.102 acc:84.375 [ Epoch4: 63/96 ] loss:0.146 acc:78.125 [ Epoch4: 64/96 ] loss:0.133 acc:84.375 [ Epoch4: 65/96 ] loss:0.142 acc:81.250 [ Epoch4: 66/96 ] loss:0.125 acc:84.375 [ Epoch4: 67/96 ] loss:0.131 acc:84.375 [ Epoch4: 68/96 ] loss:0.148 acc:81.250 [ Epoch4: 69/96 ] loss:0.120 acc:81.250 [ Epoch4: 70/96 ] loss:0.129 acc:81.250 [ Epoch4: 71/96 ] loss:0.139 acc:79.688 [ Epoch4: 72/96 ] loss:0.120 acc:84.375 [ Epoch4: 73/96 ] loss:0.083 acc:87.500 [ Epoch4: 74/96 ] loss:0.146 acc:84.375 [ Epoch4: 75/96 ] loss:0.164 acc:81.250 [ Epoch4: 76/96 ] loss:0.116 acc:89.062 [ Epoch4: 77/96 ] loss:0.147 acc:82.812 [ Epoch4: 78/96 ] loss:0.109 acc:82.812 [ Epoch4: 79/96 ] loss:0.115 acc:85.938 [ Epoch4: 80/96 ] loss:0.080 acc:89.062 [ Epoch4: 81/96 ] loss:0.158 acc:78.125 [ Epoch4: 82/96 ] loss:0.109 acc:84.375 [ Epoch4: 83/96 ] loss:0.148 acc:75.000 [ Epoch4: 84/96 ] loss:0.179 acc:73.438 [ Epoch4: 85/96 ] loss:0.144 acc:82.812 [ Epoch4: 86/96 ] loss:0.167 acc:79.688 [ Epoch4: 87/96 ] loss:0.105 acc:84.375 [ Epoch4: 88/96 ] loss:0.124 acc:84.375 [ Epoch4: 89/96 ] loss:0.130 acc:82.812 [ Epoch4: 90/96 ] loss:0.081 acc:90.625 [ Epoch4: 91/96 ] loss:0.070 acc:90.625 [ Epoch4: 92/96 ] loss:0.102 acc:87.500 [ Epoch4: 93/96 ] loss:0.089 acc:90.625 [ Epoch4: 94/96 ] loss:0.175 acc:76.562 [ Epoch4: 95/96 ] loss:0.170 acc:78.125 [ Epoch4: 96/96 ] loss:0.046 acc:15.625 
Train | Loss:0.12873 Acc: 82.161
Valid | Loss:0.13578 Acc: 80.924 
Traceback (most recent call last):
  File "/home/uceehx2/AMLS_II_assignment21_22-kaggle/main.py", line 131, in <module>
    train()
  File "/home/uceehx2/AMLS_II_assignment21_22-kaggle/main.py", line 101, in train
    training(args.model, args.batch_size, args.n_epochs, criterion, optimizer, scheduler, train_loader, val_loader, train_model, device, args.early_stop_TH)
  File "/home/uceehx2/AMLS_II_assignment21_22-kaggle/code/train_test.py", line 85, in training
    torch.save(model, "./models/" + modeltype + "/ckpt_" + str(round(total_acc/v_batch*100, 3)) + ".model")
  File "/home/uceehx2/AMLS/lib/python3.9/site-packages/torch/serialization.py", line 373, in save
    return
  File "/home/uceehx2/AMLS/lib/python3.9/site-packages/torch/serialization.py", line 214, in __exit__
    self.file_like.close()
OSError: [Errno 122] Disk quota exceeded
